{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    train_path=f\"data/file_name\"\n",
    "    test_path=f\"data/file_name\"\n",
    "    model_path=f'model'\n",
    "    n_epoch=100\n",
    "    batch_size=128\n",
    "    lr=0.001\n",
    "    loss_L1=nn.L1Loss()\n",
    "    loss_cross=nn.CrossEntropyLoss()\n",
    "    opt=torch.optim.Adam\n",
    "    \n",
    "cfg=CFG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available: True ; cudnn available: True ; num devices: 1\n",
      "Using device Quadro RTX 6000\n",
      "64 CPUs available\n"
     ]
    }
   ],
   "source": [
    "def get_device(cuda_preference=True):\n",
    "    print('cuda available:', torch.cuda.is_available(), \n",
    "        '; cudnn available:', torch.backends.cudnn.is_available(),\n",
    "        '; num devices:', torch.cuda.device_count())\n",
    "    \n",
    "    use_cuda = False if not cuda_preference else torch.cuda.is_available()\n",
    "    device = torch.device('cuda:0' if use_cuda else 'cpu')\n",
    "    device_name = torch.cuda.get_device_name(device) if use_cuda else 'cpu'\n",
    "    print('Using device', device_name)\n",
    "    return device\n",
    "\n",
    "device=get_device()\n",
    "num_cpus = os.cpu_count()\n",
    "print(num_cpus, 'CPUs available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2421592839.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[18], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    def get_dataloaders(df,cfg.batch_size):\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "def get_value(df):\n",
    "    feature=df['column_name']\n",
    "    target=df['target']\n",
    "\n",
    "    return feature.value,target.value\n",
    "\n",
    "def get_dataloaders(df,cfg.batch_size):\n",
    "    feature,target=get_value(df)\n",
    "    x_tensor=torch.Tensor(feature).to(device)\n",
    "    y_tensor=torch.Tensor(target).to(device)\n",
    "\n",
    "    full_dataset=TensorDataset(x_tensor,y_tensor)\n",
    "    train_dataset,valid_dataset=random_split(full_dataset,[0.8,0.2])\n",
    "\n",
    "    train_dataloader=DataLoader(train_dataset,batch_size=cfg.batch_size,shuffle=True)\n",
    "    valid_dataloader=DataLoader(valid_dataset,batch_size=2*cfg.batch_size)\n",
    "\n",
    "    return train_dataloader,valid_dataloader\n",
    "\n",
    "train_data,valid_data=get_dataloaders(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- validation_stepとvalidation_epoch_endとepoch_endは引数にtaskの種類を入れること"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Basic(nn.Module):\n",
    "    def training_step(self,batch,loss_function):\n",
    "        feature,target=batch\n",
    "        out=self(feature)\n",
    "        loss=loss_function(out,target)\n",
    "        return loss\n",
    "    \n",
    "    def validatio_step(self,batch,loss_function,task):\n",
    "        feature,target=batch\n",
    "        out=self(feature)\n",
    "        loss=loss_function(out,target)\n",
    "        if task == 'Regression':\n",
    "            return {'valid_loss':loss.detach() }\n",
    "        elif task == 'Classification':\n",
    "            acc=accuracy(out,target)\n",
    "            return {'val_loss':loss.detach()  , 'val_acc' : acc}\n",
    "\n",
    "    def validation_epoch_end(self, outputs,task):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean() # Combine losses\n",
    "        if task=='Regresison':\n",
    "            return {'val_loss': epoch_loss.item()}\n",
    "        elif task=='Classification':\n",
    "            batch_accs = [x['val_acc'] for x in outputs]\n",
    "            epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "            return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result,task):\n",
    "        if task =='Regression':\n",
    "            print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss']))\n",
    "\n",
    "        elif task=='Classificatioin':\n",
    "            print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch+1, result['train_loss'], result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- layersでneuralnetworkのレイヤーの数を決めるだけでいい\n",
    "- NeuralNetworkクラスでBasicを継承している"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/bdr/deep-learning/DNN/competition_base.ipynb セル 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bdr/deep-learning/DNN/competition_base.ipynb#W6sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m             \u001b[39mif\u001b[39;00m m\u001b[39m.\u001b[39mout_features \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bdr/deep-learning/DNN/competition_base.ipynb#W6sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m                 torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39minit\u001b[39m.\u001b[39mxavier_normal_(m\u001b[39m.\u001b[39mweight)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/bdr/deep-learning/DNN/competition_base.ipynb#W6sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m model\u001b[39m=\u001b[39mNeuralNetwork()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bdr/deep-learning/DNN/competition_base.ipynb#W6sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m model\n",
      "\u001b[1;32m/home/bdr/deep-learning/DNN/competition_base.ipynb セル 9\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bdr/deep-learning/DNN/competition_base.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bdr/deep-learning/DNN/competition_base.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bdr/deep-learning/DNN/competition_base.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu_stack\u001b[39m=\u001b[39mnn\u001b[39m.\u001b[39mSequential(\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/bdr/deep-learning/DNN/competition_base.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         nn\u001b[39m.\u001b[39mLinear(\u001b[39mlen\u001b[39m(feature),layers[\u001b[39m0\u001b[39m]),\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bdr/deep-learning/DNN/competition_base.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         nn\u001b[39m.\u001b[39mReLU()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bdr/deep-learning/DNN/competition_base.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bdr/deep-learning/DNN/competition_base.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(layers)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bdr/deep-learning/DNN/competition_base.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu_stack\u001b[39m.\u001b[39mappned(nn\u001b[39m.\u001b[39mDropout(\u001b[39m0.25\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feature' is not defined"
     ]
    }
   ],
   "source": [
    "layers=[64,64,32,32,16,16,8,8]\n",
    "class NeuralNetwork(Basic):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.relu_stack=nn.Sequential(\n",
    "            nn.Linear(len(feature),layers[0]),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        for i in range(len(layers)-1):\n",
    "            self.relu_stack.appned(nn.Dropout(0.25))\n",
    "            self.relu_stack.append(nn.Linear(layers[i],layers[i+1]))\n",
    "            self.relu_stack.append(nn.ReLU())\n",
    "        self.relu_stack.append(nn.Linear(layers[-1],1))\n",
    "\n",
    "    def forward(self,x):\n",
    "        output=self.relu_stack(x)\n",
    "        return output\n",
    "    \n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.kaiming_normal_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "            if m.out_features == 1:\n",
    "                torch.nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "model=NeuralNetwork()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model,valid_data):\n",
    "    model.val()\n",
    "    outputs=[model.validation_step(batch) for batch in valid_data]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit (model,train_data,valid_data,opt_func=cfg.opt,lr=cfg.lr,epochs=cfg.n_epoch):\n",
    "    history=[]\n",
    "    best_accuracy=0.0\n",
    "    optimizer=opt_func(model.parameters(),lr)\n",
    "    for epoch in range(epochs):\n",
    "        #training phase\n",
    "        model.train()\n",
    "        train_losses=[]\n",
    "        for batch in train_data:\n",
    "            loss=model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()#Batchごとに実行しているので勾配を０にしないといけない\n",
    "        #validation phase\n",
    "        result=evaluate(model,valid_data)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "\n",
    "        if history[epoch]['val_acc']>best_accuracy:\n",
    "            torch.save(model.state_dict(),'cfg.model_path/best_checkpoint.model')\n",
    "            best_accuracy=history[epoch['val_acc']]\n",
    "            print('model is saved !')\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/bdr/deep-learning/DNN/competition_base.ipynb セル 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/bdr/deep-learning/DNN/competition_base.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mapply(init_weights)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bdr/deep-learning/DNN/competition_base.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.apply(init_weights)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/bdr/deep-learning/DNN/competition_base.ipynb セル 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/bdr/deep-learning/DNN/competition_base.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m history\u001b[39m=\u001b[39mfit(model,train_data,valid_data,opt_func,lr,epochs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "history=fit(model,train_data,valid_data,opt_func,lr,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(history):\n",
    "    accuracy=[x['val_acc'] for x in history]\n",
    "    plt.plot(accuracy, '-')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Accuracy vs. No. of epochs')\n",
    "\n",
    "def plot_losses(history):\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    val_losses = [x['val_loss'] for x in history]\n",
    "    plt.plot(train_losses,color='red')\n",
    "    plt.plot(val_losses,color='blue')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss vs. No. of epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model.load_state_dict(torch.load('cfg.model_path/best_checkpoint.model'))\n",
    "test_accuracy=0.0\n",
    "for i, (feature,target) in enumerate(test_dl):\n",
    "    if torch.cuda.is_available():\n",
    "        feature=F(feature.cuda())\n",
    "        target=Variable(target.cuda())\n",
    "\n",
    "    outputs=model(feature)\n",
    "    _,prediction=torch.max(outputs.data,1)\n",
    "    test_accuracy+=int(torch.sum(prediction==target.data))\n",
    "\n",
    "test_accuracy=test_accuracy/test_count\n",
    "print(\"Test accuracy: \", test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
