{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboardの使い方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:06<00:00, 3941148.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 97674.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:09<00:00, 459163.67it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 9810212.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# datasets\n",
    "trainset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "# constant for classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorboardを使うためのセットアップ\n",
    "\n",
    "1. Summerywritingをimportする。情報をtensorboardに書くためのキーオブジェクト\n",
    "1. 単独で runs/fashion_mnist_experiment_1 フォルダを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.12.1 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "#コマンドを動かして、https://localhost:6006/ をクリックして開く　\n",
    "! tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### グラフとしてモデルを可視化する\n",
    "- InputのあとのNetのところをダブルクリックするとモデルの詳しい形がわかる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def select_n_random(data, labels, n=100):\n",
    "    '''\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\n",
    "    '''\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# select random images and their target indices\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "\n",
    "# get the class labels for each image\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "# log embeddings\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features,\n",
    "                    metadata=class_labels,\n",
    "                    label_img=images.unsqueeze(1))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. gets the probability predictions in a test_size x num_classes Tensor\n",
    "# 2. gets the preds in a test_size Tensor\n",
    "# takes ~10 seconds to run\n",
    "class_probs = []\n",
    "class_preds = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        output = net(images)\n",
    "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "        _, class_preds_batch = torch.max(output, 1)\n",
    "\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_preds.append(class_preds_batch)\n",
    "\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_preds = torch.cat(class_preds)\n",
    "\n",
    "# helper function\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_preds, global_step=0):\n",
    "    '''\n",
    "    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n",
    "    precision-recall curve\n",
    "    '''\n",
    "    tensorboard_preds = test_preds == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        tensorboard_preds,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "    writer.close()\n",
    "\n",
    "# plot all the pr curves\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.12.1 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "#コマンドを動かして、https://localhost:6006/ をクリックして開く　\n",
    "! tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
