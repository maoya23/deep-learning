{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMDb(Internet Movie Database)を使った感想のPositive,Negative分類\n",
    "\n",
    "##### 使用するアーキテクチャ\n",
    "- RNN\n",
    "- LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "from typing import List\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import vocab\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "seed = 1234\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "class Config():\n",
    "    batch_size=128\n",
    "    n_epoch=20\n",
    "    device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    emb_dim = 100\n",
    "    hid_dim = 50\n",
    "\n",
    "    checkpoint_path='model/IMDB.pt'\n",
    "config=Config()\n",
    "\n",
    "print(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_log(x):\n",
    "    return torch.log(torch.clamp(x,min=1e-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = datasets.IMDB(split='train')\n",
    "\n",
    "train_iter, valid_iter = train_iter.random_split(\n",
    "    weights={\"train\": 0.8, \"valid\": 0.2},\n",
    "    seed=seed,\n",
    "    total_length=len(list(train_iter)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "単語種数: 9937\n",
      "<unk>, <PAD>, <BOS>, <EOS>, i, am, curious, yellow, is, a, and, pretentious, steaming, pile, ., it, doesn, ', t, matter, what, one, s, political, views, are, because, this, film, can, hardly, be, taken, seriously, on, any, level, as, for, the, claim, that, frontal, male, nudity, an, automatic, ,, isn, true, ve, seen, films, with, granted, they, only, offer, some, fleeting, but, where, ?, nowhere, don, exist, same, goes, those, crappy, cable, shows, swinging, in, not, sight, indie, movies, like, brown, bunny, which, we, re, treated, to, site, of, vincent, johnson, trace, pink, visible, chloe, before, crying, (, or, ), matters\n"
     ]
    }
   ],
   "source": [
    "#tokenizerでインスタンス化\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "#counterでインスタンス化\n",
    "counter = Counter()\n",
    "\n",
    "#train_iterのlineをtokenizerを使ってcounterに加える\n",
    "for label, line in train_iter:\n",
    "    counter.update(tokenizer(line))\n",
    "\n",
    "#vocabメソッドでvocabularyをインスタンス化\n",
    "vocabulary = vocab(\n",
    "    counter,\n",
    "    min_freq=25,\n",
    "    specials=('<unk>', '<PAD>', '<BOS>', '<EOS>')\n",
    ")\n",
    "# <unk>をデフォルトに設定することにより，min_freq回以上出てこない単語は<unk>になる\n",
    "vocabulary.set_default_index(vocabulary['<unk>'])\n",
    "\n",
    "word_num = len(vocabulary)\n",
    "\n",
    "print(f\"単語種数: {word_num}\")\n",
    "print(*vocabulary.get_itos()[:100], sep=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_transform(_text,max_length=256):\n",
    "    text=[vocabulary[token] for token in tokenizer(_text)][:max_length-2]\n",
    "    text=[vocabulary['<BOS>']]+text+[vocabulary['<EOS>']]\n",
    "\n",
    "    return text,len(text)\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list,text_list,len_seq_list=[],[],[]\n",
    "\n",
    "    for _label,_text in batch:\n",
    "    # torchtext==0.15.1からはnegativeは1，positiveは2なので，-1して{0, 1}にする\n",
    "        label_list.append(_label-1)\n",
    "\n",
    "        processed_test,len_seq=text_transform(_text)\n",
    "        text_list.append(torch.tensor(processed_test))\n",
    "        len_seq_list.append(len_seq)\n",
    "\n",
    "    return torch.tensor(label_list),pad_sequence(text_list, padding_value=1).T, torch.tensor(len_seq_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader=DataLoader(\n",
    "    list(train_iter),\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "valid_dataloader=DataLoader(\n",
    "    list(valid_iter),\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTMとRNNで同じ訓練ループなので関数化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, verbose=True, path=config.checkpoint_path, patience=1):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.__early_stop = False\n",
    "        self.val_f1_score = -np.Inf\n",
    "        self.path = path\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def early_stop(self):\n",
    "        return self.__early_stop\n",
    "\n",
    "    def update(self, val_f1_score, model):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_f1_score\n",
    "            self.save_checkpoint(model, val_f1_score)\n",
    "        elif val_f1_score < self.best_score:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.__early_stop = True\n",
    "        else:\n",
    "            self.best_score = val_f1_score\n",
    "            self.save_checkpoint(model, val_f1_score)\n",
    "            self.counter = 0\n",
    "    \n",
    "    def save_checkpoint(self, model, val_f1_score):\n",
    "        if self.verbose:\n",
    "            print(f'Validation f1score increased ({self.val_f1_score:.6f} --> {val_f1_score:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_f1_score = val_f1_score\n",
    "        \n",
    "    def load_checkpoint(self, model):\n",
    "        if self.verbose:\n",
    "            print(f'Loading model from last checkpoint with validation f1score {self.val_f1_score:.6f}')\n",
    "        model.load_state_dict(torch.load(self.path))\n",
    "        return model\n",
    "\n",
    "early_stopping=EarlyStopper(patience=7,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def train(net,optimizer,n_epoch=config.n_epoch):\n",
    "    for epoch in range(n_epoch):\n",
    "        losses_train=[]\n",
    "        losses_valid=[]\n",
    "\n",
    "        net.train()\n",
    "        n_train=0\n",
    "\n",
    "        with tqdm(train_dataloader) as pbar_epoch:\n",
    "            for label,line,len_seq in pbar_epoch:\n",
    "                net.zero_grad()\n",
    "\n",
    "                t=label.to(config.device)\n",
    "                x=line.to(config.device)\n",
    "                len_seq.to(config.device)\n",
    "\n",
    "                h=net(x,torch.max(len_seq),len_seq)\n",
    "                y=torch.sigmoid(h).squeeze()#テンソル配列からサイズが１の次元を消去\n",
    "                loss=-torch.mean(t*torch_log(y)+(1-t)*torch_log(1-y))\n",
    "\n",
    "                loss.backward()  # 誤差の逆伝播\n",
    "\n",
    "                optimizer.step()  # パラメータの更新\n",
    "\n",
    "                losses_train.append(loss.tolist())\n",
    "\n",
    "                n_train += t.size()[0]\n",
    "\n",
    "                pbar_epoch.set_postfix(OrderedDict(train_loss=np.mean(losses_train)))\n",
    "            # Valid\n",
    "            t_valid = []\n",
    "            y_pred = []\n",
    "            net.eval()\n",
    "        with tqdm(valid_dataloader) as pbar_epoch:\n",
    "            for label, line, len_seq in pbar_epoch:\n",
    "\n",
    "                t = label.to(config.device) # テンソルをGPUに移動\n",
    "                x = line.to(config.device)\n",
    "                len_seq.to(config.device)\n",
    "\n",
    "                h = net(x, torch.max(len_seq), len_seq)\n",
    "                y = torch.sigmoid(h).squeeze()\n",
    "\n",
    "                loss = -torch.mean(t*torch_log(y) + (1 - t)*torch_log(1 - y))\n",
    "\n",
    "                pred = y.round().squeeze()  # 0.5以上の値を持つ要素を正ラベルと予測する\n",
    "\n",
    "                t_valid.extend(t.tolist())\n",
    "                y_pred.extend(pred.tolist())\n",
    "\n",
    "                losses_valid.append(loss.tolist())\n",
    "                val_f1_score=f1_score(t_valid, y_pred, average='macro')\n",
    "\n",
    "            early_stopping.update(val_f1_score,model=net)\n",
    "\n",
    "            print('EPOCH: {}, Train Loss: {:.3f}, Valid Loss: {:.3f}, Validation F1: {:.3f}'.format(\n",
    "                epoch+1,\n",
    "                np.mean(losses_train),\n",
    "                np.mean(losses_valid),\n",
    "                f1_score(t_valid, y_pred, average='macro')\n",
    "            ))\n",
    "            pbar_epoch.set_postfix(OrderedDict(valid_loss=np.mean(losses_valid),f1_score=f1_score(t_valid, y_pred, average='macro')))\n",
    "            if early_stopping.early_stop:\n",
    "                print('Early Stopping!')\n",
    "                break\n",
    "\n",
    "    net=early_stopping.load_checkpoint(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding層の実装\n",
    "- 単語を離散的なIDから連続的なベクトルに変換する\n",
    "- 埋め込み行列も学習に使われるパラメータで単語間の類似度を示す\n",
    "- 埋め込み行列はランダムに初期化する\n",
    "\n",
    "以下の仮想的な状況を考える<br>\n",
    "辞書: {'猫': 0, 'は': 1, '魚': 2, 'が': 3, '好き': 4, 'です': 5}\n",
    "\n",
    "V (埋め込み行列):<br>\n",
    "0: [0.1, 0.3, 0.2]  # 「猫」の埋め込みベクトル<br>\n",
    "1: [0.2, 0.1, 0.3]  # 「は」の埋め込みベクトル<br>\n",
    "2: [0.3, 0.2, 0.1]  # 「魚」の埋め込みベクトル<br>\n",
    "3: [0.1, 0.2, 0.3]  # 「が」の埋め込みベクトル<br>\n",
    "4: [0.2, 0.3, 0.1]  # 「好き」の埋め込みベクトル<br>\n",
    "5: [0.3, 0.1, 0.2]  # 「です」の埋め込みベクトル<br>\n",
    "\n",
    "これに対して以下の文があったとすると<br>\n",
    "x (単語ID):<br>\n",
    "文1: [0, 1, 2, 3, 4, 5]  # 「猫は魚が好きです」<br>\n",
    "文2: [2, 1, 0, 3, 4, 5]  # 「魚は猫が好きです」<br>\n",
    "\n",
    "出力のテンソルは以下のようになる<br>\n",
    "\n",
    "出力テンソル:<br>\n",
    "文1: [[0.1, 0.3, 0.2], [0.2, 0.1, 0.3], [0.3, 0.2, 0.1], [0.1, 0.2, 0.3], [0.2, 0.3, 0.1], [0.3, 0.1, 0.2]]  # 「猫は魚が好きです」<br>\n",
    "文2: [[0.3, 0.2, 0.1], [0.2, 0.1, 0.3], [0.1, 0.3, 0.2], [0.1, 0.2, 0.3], [0.2, 0.3, 0.1], [0.3, 0.1, 0.2]]  # 「魚は猫が好きです」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self,emb_dim,vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding_matrix=nn.Parameter(torch.rand((vocab_size,emb_dim),\n",
    "                                                    dtype=torch.float))\n",
    "#Embeddingの実行\n",
    "    def forward(self,x):\n",
    "        return F.embedding(x,self.embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim):\n",
    "        super().__init__()\n",
    "        self.hid_dim = hid_dim\n",
    "        glorot = 6 / (in_dim + hid_dim*2)\n",
    "        self.W = nn.Parameter(torch.tensor(np.random.uniform(\n",
    "                        low=-np.sqrt(glorot),\n",
    "                        high=np.sqrt(glorot),\n",
    "                        size=(in_dim + hid_dim, hid_dim)\n",
    "                    ).astype('float32')))\n",
    "        self.b = nn.Parameter(torch.tensor(np.zeros([hid_dim]).astype('float32')))\n",
    "\n",
    "    def function(self, h, x):\n",
    "        return torch.tanh(torch.matmul(torch.cat([h, x], dim=1), self.W) + self.b)\n",
    "\n",
    "    def forward(self, x, len_seq_max=0, init_state=None):\n",
    "        x = x.transpose(0, 1)  # 系列のバッチ処理のため、次元の順番を「系列、バッチ」の順に入れ替える\n",
    "        state = init_state\n",
    "\n",
    "        if init_state is None:  # 初期値を設定しない場合は0で初期化する\n",
    "            state = torch.zeros((x[0].size()[0], self.hid_dim)).to(x.device)\n",
    "\n",
    "        size = list(state.unsqueeze(0).size())\n",
    "        size[0] = 0\n",
    "        output = torch.empty(size, dtype=torch.float).to(x.device)  # 一旦空テンソルを定義して順次出力を追加する\n",
    "\n",
    "        if len_seq_max == 0:\n",
    "            len_seq_max = x.size(0)\n",
    "        for i in range(len_seq_max):\n",
    "            state = self.function(state, x[i])\n",
    "            output = torch.cat([output, state.unsqueeze(0)])  # 出力系列の追加\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceTaggingNet(nn.Module):\n",
    "    def __init__(self, word_num, emb_dim, hid_dim):\n",
    "        super().__init__()\n",
    "        self.emb = Embedding(emb_dim, word_num)\n",
    "        self.rnn = RNN(emb_dim, hid_dim)\n",
    "        self.linear = nn.Linear(hid_dim, 1)\n",
    "\n",
    "    def forward(self, x, len_seq_max=0, len_seq=None, init_state=None):\n",
    "        h = self.emb(x)\n",
    "        h = self.rnn(h, len_seq_max, init_state)\n",
    "        if len_seq is not None:\n",
    "            # 系列が終わった時点での出力を取る必要があるので len_seq を元に集約する\n",
    "            h = h[len_seq - 1, list(range(len(x))), :]\n",
    "        else:\n",
    "            h = h[-1]\n",
    "        y = self.linear(h)\n",
    "        return y\n",
    "    \n",
    "# RNNのモジュールを使った場合のモデルを構築する\n",
    "    \n",
    "class SeqenceTaggingNet2(nn.Module):\n",
    "    def __init__(self,word_num,emb_dim,hid_dim):\n",
    "        self.emb=Embedding(emb_dim,word_num)\n",
    "        self.rnn=nn.RNN(emb_dim,hid_dim,1,batch_first=True)\n",
    "        self.linear=nn.Linear(hid_dim,1)\n",
    "\n",
    "    def forward(self, x, len_seq_max=0, len_seq=None, init_state=None):\n",
    "        h = self.emb(x)\n",
    "        if len_seq_max > 0:\n",
    "            h, _ = self.rnn(h[:, 0:len_seq_max, :], init_state)\n",
    "        else:\n",
    "            h, _ = self.rnn(h, init_state)\n",
    "        h = h.transpose(0, 1)\n",
    "        if len_seq is not None:\n",
    "            # 系列が終わった時点での出力を取る必要があるので len_seq を元に集約する\n",
    "            h = h[len_seq - 1, list(range(len(x))), :]\n",
    "        else:\n",
    "            h = h[-1]\n",
    "        y = self.linear(h)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 2/157 [00:00<00:17,  8.71it/s, train_loss=0.752]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:17<00:00,  8.91it/s, train_loss=0.692]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1score increased (-inf --> 0.462919).  Saving model ...\n",
      "EPOCH: 1, Train Loss: 0.692, Valid Loss: 0.687, Validation F1: 0.463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:17<00:00,  8.74it/s, train_loss=0.656]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1score increased (0.462919 --> 0.596929).  Saving model ...\n",
      "EPOCH: 2, Train Loss: 0.656, Valid Loss: 0.638, Validation F1: 0.597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:18<00:00,  8.69it/s, train_loss=0.636]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 7\n",
      "EPOCH: 3, Train Loss: 0.636, Valid Loss: 0.684, Validation F1: 0.532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:17<00:00,  8.73it/s, train_loss=0.625]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1score increased (0.596929 --> 0.606960).  Saving model ...\n",
      "EPOCH: 4, Train Loss: 0.625, Valid Loss: 0.665, Validation F1: 0.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:18<00:00,  8.71it/s, train_loss=0.537]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1score increased (0.606960 --> 0.624342).  Saving model ...\n",
      "EPOCH: 5, Train Loss: 0.537, Valid Loss: 0.658, Validation F1: 0.624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:18<00:00,  8.70it/s, train_loss=0.478]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 7\n",
      "EPOCH: 6, Train Loss: 0.478, Valid Loss: 0.720, Validation F1: 0.589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:18<00:00,  8.67it/s, train_loss=0.401]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1score increased (0.624342 --> 0.657565).  Saving model ...\n",
      "EPOCH: 7, Train Loss: 0.401, Valid Loss: 0.692, Validation F1: 0.658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:17<00:00,  8.79it/s, train_loss=0.319]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 7\n",
      "EPOCH: 8, Train Loss: 0.319, Valid Loss: 0.778, Validation F1: 0.638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:18<00:00,  8.70it/s, train_loss=0.266]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 7\n",
      "EPOCH: 9, Train Loss: 0.266, Valid Loss: 0.847, Validation F1: 0.651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:17<00:00,  8.78it/s, train_loss=0.214]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1score increased (0.657565 --> 0.726960).  Saving model ...\n",
      "EPOCH: 10, Train Loss: 0.214, Valid Loss: 0.752, Validation F1: 0.727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:18<00:00,  8.72it/s, train_loss=0.304]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 7\n",
      "EPOCH: 11, Train Loss: 0.304, Valid Loss: 0.915, Validation F1: 0.575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:17<00:00,  8.78it/s, train_loss=0.302]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 7\n",
      "EPOCH: 12, Train Loss: 0.302, Valid Loss: 0.860, Validation F1: 0.653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:17<00:00,  8.76it/s, train_loss=0.266]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 7\n",
      "EPOCH: 13, Train Loss: 0.266, Valid Loss: 1.107, Validation F1: 0.600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:17<00:00,  8.83it/s, train_loss=0.192]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 4 out of 7\n",
      "EPOCH: 14, Train Loss: 0.192, Valid Loss: 1.055, Validation F1: 0.638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:17<00:00,  9.00it/s, train_loss=0.146]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 5 out of 7\n",
      "EPOCH: 15, Train Loss: 0.146, Valid Loss: 1.111, Validation F1: 0.640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:17<00:00,  9.07it/s, train_loss=0.122]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 6 out of 7\n",
      "EPOCH: 16, Train Loss: 0.122, Valid Loss: 1.187, Validation F1: 0.642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:17<00:00,  8.78it/s, train_loss=0.101] \n",
      "100%|██████████| 40/40 [00:02<00:00, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 7 out of 7\n",
      "EPOCH: 17, Train Loss: 0.101, Valid Loss: 1.320, Validation F1: 0.631\n",
      "Early Stopping!\n",
      "Loading model from last checkpoint with validation f1score 0.726960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net = SequenceTaggingNet(word_num, config.emb_dim, config.hid_dim)\n",
    "net.to(config.device)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "\n",
    "train(net, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTMを用いた実装\n",
    "\n",
    "- 入力ゲート: $\\hspace{20mm}\\boldsymbol{i}_t = \\mathrm{\\sigma} \\left(\\boldsymbol{W}_i \\left[\\begin{array}{c} \\boldsymbol{x}_t \\\\ \\boldsymbol{h}_{t-1} \\end{array}\\right] + \\boldsymbol{b}_i\\right)$\n",
    "- 忘却ゲート: $\\hspace{20mm}\\boldsymbol{f}_t = \\mathrm{\\sigma} \\left(\\boldsymbol{W}_f \\left[\\begin{array}{c} \\boldsymbol{x}_t \\\\ \\boldsymbol{h}_{t-1} \\end{array}\\right] + \\boldsymbol{b}_f\\right)$  \n",
    "- 出力ゲート: $\\hspace{20mm}\\boldsymbol{o}_t = \\mathrm{\\sigma} \\left(\\boldsymbol{W}_o \\left[\\begin{array}{c} \\boldsymbol{x}_t \\\\ \\boldsymbol{h}_{t-1} \\end{array}\\right] + \\boldsymbol{b}_o\\right)$  \n",
    "- セル:　　　 $\\hspace{20mm}\\boldsymbol{c}_t = \\boldsymbol{f}_t \\odot \\boldsymbol{c}_{t-1} + \\boldsymbol{i}_t \\odot \\tanh \\left(\\boldsymbol{W}_c \\left[\\begin{array}{c} \\boldsymbol{x}_t \\\\ \\boldsymbol{h}_{t-1} \\end{array}\\right] + \\boldsymbol{b}_c\\right)$\n",
    "- 隠れ状態: 　$\\hspace{20mm}\\boldsymbol{h}_t = \\boldsymbol{o}_t \\odot \\tanh \\left(\\boldsymbol{c}_t \\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceTaggingNet4(nn.Module):\n",
    "    def __init__(self, word_num, emb_dim, hid_dim):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(word_num, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hid_dim, 1, batch_first=True)  # nn.LSTMの使用\n",
    "        self.linear = nn.Linear(hid_dim, 1)\n",
    "    \n",
    "    def forward(self, x, len_seq_max=0, len_seq=None, init_state=None):\n",
    "        h = self.emb(x)\n",
    "        if len_seq_max > 0:\n",
    "            h, _ = self.lstm(h[:, 0:len_seq_max, :], init_state)\n",
    "        else:\n",
    "            h, _ = self.lstm(h, init_state)\n",
    "        h = h.transpose(0, 1)\n",
    "        if len_seq is not None:\n",
    "            h = h[len_seq - 1, list(range(len(x))), :]\n",
    "        else:\n",
    "            h = h[-1]\n",
    "        y = self.linear(h)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:05<00:00, 29.35it/s, train_loss=0.674]\n",
      "100%|██████████| 40/40 [00:01<00:00, 31.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1score increased (-inf --> 0.618530).  Saving model ...\n",
      "EPOCH: 1, Train Loss: 0.674, Valid Loss: 0.635, Validation F1: 0.619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:05<00:00, 28.99it/s, train_loss=0.599]\n",
      "100%|██████████| 40/40 [00:01<00:00, 30.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1score increased (0.618530 --> 0.710577).  Saving model ...\n",
      "EPOCH: 2, Train Loss: 0.599, Valid Loss: 0.585, Validation F1: 0.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:05<00:00, 29.15it/s, train_loss=0.53] \n",
      "100%|██████████| 40/40 [00:01<00:00, 30.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1score increased (0.710577 --> 0.766393).  Saving model ...\n",
      "EPOCH: 3, Train Loss: 0.530, Valid Loss: 0.514, Validation F1: 0.766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:05<00:00, 28.77it/s, train_loss=0.463]\n",
      "100%|██████████| 40/40 [00:01<00:00, 31.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1score increased (0.766393 --> 0.795515).  Saving model ...\n",
      "EPOCH: 4, Train Loss: 0.463, Valid Loss: 0.477, Validation F1: 0.796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:05<00:00, 29.15it/s, train_loss=0.398]\n",
      "100%|██████████| 40/40 [00:01<00:00, 30.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1score increased (0.795515 --> 0.803995).  Saving model ...\n",
      "EPOCH: 5, Train Loss: 0.398, Valid Loss: 0.447, Validation F1: 0.804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:05<00:00, 29.15it/s, train_loss=0.372]\n",
      "100%|██████████| 40/40 [00:01<00:00, 30.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1score increased (0.803995 --> 0.825185).  Saving model ...\n",
      "EPOCH: 6, Train Loss: 0.372, Valid Loss: 0.420, Validation F1: 0.825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:05<00:00, 28.95it/s, train_loss=0.322]\n",
      "100%|██████████| 40/40 [00:01<00:00, 30.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 7\n",
      "EPOCH: 7, Train Loss: 0.322, Valid Loss: 0.429, Validation F1: 0.816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:05<00:00, 29.01it/s, train_loss=0.288]\n",
      "100%|██████████| 40/40 [00:01<00:00, 30.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 7\n",
      "EPOCH: 8, Train Loss: 0.288, Valid Loss: 0.446, Validation F1: 0.814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:05<00:00, 29.07it/s, train_loss=0.257]\n",
      "100%|██████████| 40/40 [00:01<00:00, 30.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1score increased (0.825185 --> 0.828163).  Saving model ...\n",
      "EPOCH: 9, Train Loss: 0.257, Valid Loss: 0.442, Validation F1: 0.828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:05<00:00, 28.91it/s, train_loss=0.225]\n",
      "100%|██████████| 40/40 [00:01<00:00, 30.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 7\n",
      "EPOCH: 10, Train Loss: 0.225, Valid Loss: 0.484, Validation F1: 0.821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:05<00:00, 28.85it/s, train_loss=0.208]\n",
      "100%|██████████| 40/40 [00:01<00:00, 29.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 7\n",
      "EPOCH: 11, Train Loss: 0.208, Valid Loss: 0.421, Validation F1: 0.825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:05<00:00, 28.68it/s, train_loss=0.177]\n",
      "100%|██████████| 40/40 [00:01<00:00, 30.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1score increased (0.828163 --> 0.851991).  Saving model ...\n",
      "EPOCH: 12, Train Loss: 0.177, Valid Loss: 0.431, Validation F1: 0.852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:05<00:00, 28.86it/s, train_loss=0.158]\n",
      "100%|██████████| 40/40 [00:01<00:00, 30.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 7\n",
      "EPOCH: 13, Train Loss: 0.158, Valid Loss: 0.463, Validation F1: 0.841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:05<00:00, 28.87it/s, train_loss=0.181]\n",
      "100%|██████████| 40/40 [00:01<00:00, 30.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 7\n",
      "EPOCH: 14, Train Loss: 0.181, Valid Loss: 0.562, Validation F1: 0.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:05<00:00, 29.49it/s, train_loss=0.485]\n",
      "100%|██████████| 40/40 [00:01<00:00, 31.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 7\n",
      "EPOCH: 15, Train Loss: 0.485, Valid Loss: 0.655, Validation F1: 0.600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:05<00:00, 29.05it/s, train_loss=0.604]\n",
      "100%|██████████| 40/40 [00:01<00:00, 31.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 4 out of 7\n",
      "EPOCH: 16, Train Loss: 0.604, Valid Loss: 0.579, Validation F1: 0.690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:05<00:00, 29.09it/s, train_loss=0.404]\n",
      "100%|██████████| 40/40 [00:01<00:00, 30.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 5 out of 7\n",
      "EPOCH: 17, Train Loss: 0.404, Valid Loss: 0.432, Validation F1: 0.808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:05<00:00, 29.21it/s, train_loss=0.301]\n",
      "100%|██████████| 40/40 [00:01<00:00, 31.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 6 out of 7\n",
      "EPOCH: 18, Train Loss: 0.301, Valid Loss: 0.402, Validation F1: 0.839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:05<00:00, 29.22it/s, train_loss=0.249]\n",
      "100%|██████████| 40/40 [00:01<00:00, 30.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 7 out of 7\n",
      "EPOCH: 19, Train Loss: 0.249, Valid Loss: 0.430, Validation F1: 0.834\n",
      "Early Stopping!\n",
      "Loading model from last checkpoint with validation f1score 0.851991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "early_stopping=EarlyStopper(patience=7,verbose=True,path='./model/IMBD_LSTM.pt')\n",
    "net = SequenceTaggingNet4(word_num, config.emb_dim, config.hid_dim)\n",
    "net.to(config.device)\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "\n",
    "train(net, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
