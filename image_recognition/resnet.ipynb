{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNetの実装\n",
    "残差ブロックを実装することで勾配の消失を防ぎ学習の精度を上げたモデル。<br>\n",
    "参考にしたページ：https://qiita.com/tchih11/items/377cbf9162e78a639958<br>\n",
    "例によって今回もCifar-10データセットに対してモデルを作成して実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\n",
    "    'BatchSize':128,\n",
    "    'seed':42,\n",
    "    'n_epochs' : 50,\n",
    "    'lr' : 0.001\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Train data number:40000, Valid data number: 10000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainval_dataset = datasets.CIFAR10('../data/cifar10', train=True,download=True,transform=transforms.ToTensor())\n",
    "\n",
    "# 前処理を定義\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "trainval_dataset = datasets.CIFAR10('../data/cifar10', train=True, transform=transform)\n",
    "\n",
    "# trainとvalidに分割\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(trainval_dataset, [len(trainval_dataset)-10000, 10000],generator=torch.Generator().manual_seed(config['seed']))\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config['BatchSize'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "dataloader_valid = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config['BatchSize'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(\"Train data number:{}, Valid data number: {}\".format(len(train_dataset), len(val_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class block(nn.Module):\n",
    "    def __init__(self, first_conv_in_channels, first_conv_out_channels, identity_conv=None, stride=1):\n",
    "        \"\"\"\n",
    "        残差ブロックを作成するクラス\n",
    "        Args:\n",
    "            first_conv_in_channels : 1番目のconv層（1×1）のinput channel数\n",
    "            first_conv_out_channels : 1番目のconv層（1×1）のoutput channel数\n",
    "            identity_conv : channel数調整用のconv層\n",
    "            stride : 3×3conv層におけるstide数。sizeを半分にしたいときは2に設定\n",
    "        \"\"\"        \n",
    "        super(block, self).__init__()\n",
    "\n",
    "        # 1番目のconv層（1×1）\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            first_conv_in_channels, first_conv_out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(first_conv_out_channels)\n",
    "\n",
    "        # 2番目のconv層（3×3）\n",
    "        # パターン3の時はsizeを変更できるようにstrideは可変\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            first_conv_out_channels, first_conv_out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(first_conv_out_channels)\n",
    "\n",
    "        # 3番目のconv層（1×1）\n",
    "        # output channelはinput channelの4倍になる\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            first_conv_out_channels, first_conv_out_channels*4, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(first_conv_out_channels*4)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # identityのchannel数の調整が必要な場合はconv層（1×1）を用意、不要な場合はNone\n",
    "        self.identity_conv = identity_conv\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        identity = x.clone()  # 入力を保持する\n",
    "\n",
    "        x = self.conv1(x)  # 1×1の畳み込み\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)  # 3×3の畳み込み（パターン3の時はstrideが2になるため、ここでsizeが半分になる）\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)  # 1×1の畳み込み\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        # 必要な場合はconv層（1×1）を通してidentityのchannel数の調整してから足す\n",
    "        if self.identity_conv is not None:\n",
    "            identity = self.identity_conv(identity)\n",
    "        x += identity\n",
    "\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        # conv1はアーキテクチャ通りにベタ打ち\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # conv2_xはサイズの変更は不要のため、strideは1\n",
    "        self.conv2_x = self._make_layer(block, 3, res_block_in_channels=64, first_conv_out_channels=64, stride=1)\n",
    "\n",
    "        # conv3_x以降はサイズの変更をする必要があるため、strideは2\n",
    "        self.conv3_x = self._make_layer(block, 4, res_block_in_channels=256,  first_conv_out_channels=128, stride=2)\n",
    "        self.conv4_x = self._make_layer(block, 6, res_block_in_channels=512,  first_conv_out_channels=256, stride=2)\n",
    "        self.conv5_x = self._make_layer(block, 3, res_block_in_channels=1024, first_conv_out_channels=512, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512*4, num_classes)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = self.conv1(x)   # in:(3,224*224)、out:(64,112*112)\n",
    "        x = self.bn1(x)     # in:(64,112*112)、out:(64,112*112)\n",
    "        x = self.relu(x)    # in:(64,112*112)、out:(64,112*112)\n",
    "        x = self.maxpool(x) # in:(64,112*112)、out:(64,56*56)\n",
    "\n",
    "        x = self.conv2_x(x)  # in:(64,56*56)  、out:(256,56*56)\n",
    "        x = self.conv3_x(x)  # in:(256,56*56) 、out:(512,28*28)\n",
    "        x = self.conv4_x(x)  # in:(512,28*28) 、out:(1024,14*14)\n",
    "        x = self.conv5_x(x)  # in:(1024,14*14)、out:(2048,7*7)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _make_layer(self, block, num_res_blocks, res_block_in_channels, first_conv_out_channels, stride):\n",
    "        layers = []\n",
    "\n",
    "        # 1つ目の残差ブロックではchannel調整、及びsize調整が発生する\n",
    "        # identifyを足す前に1×1のconv層を追加し、サイズ調整が必要な場合はstrideを2に設定\n",
    "        identity_conv = nn.Conv2d(res_block_in_channels, first_conv_out_channels*4, kernel_size=1,stride=stride)\n",
    "        layers.append(block(res_block_in_channels, first_conv_out_channels, identity_conv, stride))\n",
    "\n",
    "        # 2つ目以降のinput_channel数は1つ目のoutput_channelの4倍\n",
    "        in_channels = first_conv_out_channels*4\n",
    "\n",
    "        # channel調整、size調整は発生しないため、identity_convはNone、strideは1\n",
    "        for i in range(num_res_blocks - 1):\n",
    "            layers.append(block(in_channels, first_conv_out_channels, identity_conv=None, stride=1))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "model=ResNet(block,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def init_weights(m):  # Heの初期化\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        torch.nn.init.kaiming_normal_(m.weight)\n",
    "        m.bias.data.fill_(0.0)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "device='cuda'\n",
    "model.to(device)\n",
    "optimizer2 = optim.Adam(model.parameters(), lr=config['lr'])\n",
    "loss_function = nn.CrossEntropyLoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1, Train [Loss: 2.111, Accuracy: 0.395], Valid [Loss: 1.480, Accuracy: 0.469]]\n",
      "EPOCH: 2, Train [Loss: 1.394, Accuracy: 0.513], Valid [Loss: 1.431, Accuracy: 0.491]]\n",
      "EPOCH: 3, Train [Loss: 1.340, Accuracy: 0.550], Valid [Loss: 1.571, Accuracy: 0.486]]\n",
      "EPOCH: 4, Train [Loss: 1.361, Accuracy: 0.541], Valid [Loss: 1.527, Accuracy: 0.470]]\n",
      "EPOCH: 5, Train [Loss: 1.083, Accuracy: 0.620], Valid [Loss: 1.027, Accuracy: 0.642]]\n",
      "EPOCH: 6, Train [Loss: 0.967, Accuracy: 0.664], Valid [Loss: 1.247, Accuracy: 0.568]]\n",
      "EPOCH: 7, Train [Loss: 0.838, Accuracy: 0.708], Valid [Loss: 1.250, Accuracy: 0.592]]\n",
      "EPOCH: 8, Train [Loss: 0.683, Accuracy: 0.760], Valid [Loss: 1.060, Accuracy: 0.648]]\n",
      "EPOCH: 9, Train [Loss: 0.638, Accuracy: 0.779], Valid [Loss: 0.964, Accuracy: 0.679]]\n",
      "EPOCH: 10, Train [Loss: 0.641, Accuracy: 0.780], Valid [Loss: 1.060, Accuracy: 0.648]]\n",
      "EPOCH: 11, Train [Loss: 0.665, Accuracy: 0.770], Valid [Loss: 0.968, Accuracy: 0.692]]\n",
      "EPOCH: 12, Train [Loss: 0.420, Accuracy: 0.856], Valid [Loss: 1.086, Accuracy: 0.665]]\n",
      "EPOCH: 13, Train [Loss: 0.344, Accuracy: 0.880], Valid [Loss: 1.061, Accuracy: 0.681]]\n",
      "EPOCH: 14, Train [Loss: 0.295, Accuracy: 0.897], Valid [Loss: 1.228, Accuracy: 0.666]]\n",
      "EPOCH: 15, Train [Loss: 0.251, Accuracy: 0.912], Valid [Loss: 1.079, Accuracy: 0.701]]\n",
      "EPOCH: 16, Train [Loss: 0.227, Accuracy: 0.920], Valid [Loss: 1.205, Accuracy: 0.685]]\n",
      "EPOCH: 17, Train [Loss: 0.196, Accuracy: 0.933], Valid [Loss: 1.237, Accuracy: 0.678]]\n",
      "EPOCH: 18, Train [Loss: 0.182, Accuracy: 0.936], Valid [Loss: 1.428, Accuracy: 0.662]]\n",
      "EPOCH: 19, Train [Loss: 0.158, Accuracy: 0.946], Valid [Loss: 1.242, Accuracy: 0.701]]\n",
      "EPOCH: 20, Train [Loss: 0.164, Accuracy: 0.943], Valid [Loss: 1.229, Accuracy: 0.696]]\n",
      "EPOCH: 21, Train [Loss: 0.234, Accuracy: 0.927], Valid [Loss: 2.286, Accuracy: 0.352]]\n",
      "EPOCH: 22, Train [Loss: 0.654, Accuracy: 0.789], Valid [Loss: 1.067, Accuracy: 0.693]]\n",
      "EPOCH: 23, Train [Loss: 0.183, Accuracy: 0.937], Valid [Loss: 1.155, Accuracy: 0.696]]\n",
      "EPOCH: 24, Train [Loss: 0.111, Accuracy: 0.961], Valid [Loss: 1.258, Accuracy: 0.710]]\n",
      "EPOCH: 25, Train [Loss: 0.085, Accuracy: 0.971], Valid [Loss: 1.279, Accuracy: 0.713]]\n",
      "EPOCH: 26, Train [Loss: 0.073, Accuracy: 0.975], Valid [Loss: 1.442, Accuracy: 0.697]]\n",
      "EPOCH: 27, Train [Loss: 0.088, Accuracy: 0.970], Valid [Loss: 1.693, Accuracy: 0.662]]\n",
      "EPOCH: 28, Train [Loss: 0.091, Accuracy: 0.969], Valid [Loss: 1.467, Accuracy: 0.686]]\n",
      "EPOCH: 29, Train [Loss: 0.080, Accuracy: 0.972], Valid [Loss: 1.313, Accuracy: 0.720]]\n",
      "EPOCH: 30, Train [Loss: 0.084, Accuracy: 0.972], Valid [Loss: 1.449, Accuracy: 0.688]]\n",
      "EPOCH: 31, Train [Loss: 0.625, Accuracy: 0.820], Valid [Loss: 1.305, Accuracy: 0.542]]\n",
      "EPOCH: 32, Train [Loss: 0.994, Accuracy: 0.671], Valid [Loss: 0.903, Accuracy: 0.703]]\n",
      "EPOCH: 33, Train [Loss: 0.366, Accuracy: 0.874], Valid [Loss: 0.971, Accuracy: 0.726]]\n",
      "EPOCH: 34, Train [Loss: 0.137, Accuracy: 0.955], Valid [Loss: 1.150, Accuracy: 0.725]]\n",
      "EPOCH: 35, Train [Loss: 0.080, Accuracy: 0.973], Valid [Loss: 1.409, Accuracy: 0.707]]\n",
      "EPOCH: 36, Train [Loss: 0.064, Accuracy: 0.978], Valid [Loss: 1.431, Accuracy: 0.723]]\n",
      "EPOCH: 37, Train [Loss: 0.067, Accuracy: 0.977], Valid [Loss: 1.579, Accuracy: 0.690]]\n",
      "EPOCH: 38, Train [Loss: 0.059, Accuracy: 0.980], Valid [Loss: 1.537, Accuracy: 0.710]]\n",
      "EPOCH: 39, Train [Loss: 0.065, Accuracy: 0.977], Valid [Loss: 1.388, Accuracy: 0.714]]\n",
      "EPOCH: 40, Train [Loss: 0.050, Accuracy: 0.983], Valid [Loss: 1.376, Accuracy: 0.736]]\n",
      "EPOCH: 41, Train [Loss: 0.062, Accuracy: 0.979], Valid [Loss: 1.432, Accuracy: 0.718]]\n",
      "EPOCH: 42, Train [Loss: 0.064, Accuracy: 0.978], Valid [Loss: 1.366, Accuracy: 0.719]]\n",
      "EPOCH: 43, Train [Loss: 0.049, Accuracy: 0.984], Valid [Loss: 1.363, Accuracy: 0.731]]\n",
      "EPOCH: 44, Train [Loss: 0.062, Accuracy: 0.978], Valid [Loss: 1.380, Accuracy: 0.727]]\n",
      "EPOCH: 45, Train [Loss: 0.057, Accuracy: 0.981], Valid [Loss: 1.409, Accuracy: 0.714]]\n",
      "EPOCH: 46, Train [Loss: 0.059, Accuracy: 0.980], Valid [Loss: 1.391, Accuracy: 0.718]]\n",
      "EPOCH: 47, Train [Loss: 0.051, Accuracy: 0.983], Valid [Loss: 1.359, Accuracy: 0.726]]\n",
      "EPOCH: 48, Train [Loss: 0.058, Accuracy: 0.980], Valid [Loss: 1.292, Accuracy: 0.726]]\n",
      "EPOCH: 49, Train [Loss: 0.200, Accuracy: 0.940], Valid [Loss: 1.120, Accuracy: 0.706]]\n",
      "EPOCH: 50, Train [Loss: 0.111, Accuracy: 0.963], Valid [Loss: 1.436, Accuracy: 0.720]]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(config['n_epochs']):\n",
    "    losses_train = []\n",
    "    losses_valid = []\n",
    "\n",
    "    model.train()\n",
    "    n_train = 0\n",
    "    acc_train = 0\n",
    "    for x, t in dataloader_train:\n",
    "        n_train += t.size()[0]\n",
    "\n",
    "        model.zero_grad()  # 勾配の初期化\n",
    "\n",
    "        x = x.to(device)  # テンソルをGPUに移動\n",
    "        t = t.to(device)\n",
    "\n",
    "        y = model.forward(x)  # 順伝播\n",
    "\n",
    "\n",
    "        loss = loss_function(y, t)  # 誤差(クロスエントロピー誤差関数)の計算\n",
    "\n",
    "        loss.backward()  # 誤差の逆伝播\n",
    "\n",
    "        optimizer2.step()  # パラメータの更新\n",
    "\n",
    "        pred = y.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n",
    "\n",
    "        acc_train += (pred == t).float().sum().item()\n",
    "        losses_train.append(loss.tolist())\n",
    "\n",
    "    model.eval()\n",
    "    n_val = 0\n",
    "    acc_val = 0\n",
    "    for x, t in dataloader_valid:\n",
    "        n_val += t.size()[0]\n",
    "\n",
    "        x = x.to(device)  # テンソルをGPUに移動\n",
    "        t = t.to(device)\n",
    "\n",
    "        y = model.forward(x)  # 順伝播\n",
    "\n",
    "        loss = loss_function(y, t)  # 誤差(クロスエントロピー誤差関数)の計算\n",
    "\n",
    "        pred = y.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n",
    "\n",
    "        acc_val += (pred == t).float().sum().item()\n",
    "        losses_valid.append(loss.tolist())\n",
    "\n",
    "    print('EPOCH: {}, Train [Loss: {:.3f}, Accuracy: {:.3f}], Valid [Loss: {:.3f}, Accuracy: {:.3f}]]'.format(\n",
    "        epoch+1,\n",
    "        np.mean(losses_train),\n",
    "        acc_train/n_train,\n",
    "        np.mean(losses_valid),\n",
    "        acc_val/n_val,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:12<00:00, 13895085.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Accuracy of the network on the 10000 test images: 71 %\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor() )\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "# 勾配を記憶せず（学習せずに）に計算を行う\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device),data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
