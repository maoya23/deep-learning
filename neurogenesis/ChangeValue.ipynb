{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9f3b9a3310>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\n",
    "    'BatchSize':256,\n",
    "    'seed':42,\n",
    "    'n_epochs' : 200,\n",
    "    'lr' : 0.001\n",
    "}\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Train data number:40000, Valid data number: 10000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainval_dataset = datasets.CIFAR10('../data/cifar10', train=True,download=True,transform=transforms.ToTensor())\n",
    "\n",
    "# 前処理を定義\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "trainval_dataset = datasets.CIFAR10('../data/cifar10', train=True, transform=transform)\n",
    "\n",
    "# trainとvalidに分割\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(trainval_dataset, [len(trainval_dataset)-10000, 10000],generator=torch.Generator().manual_seed(config['seed']))\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config['BatchSize'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "dataloader_valid = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config['BatchSize'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(\"Train data number:{}, Valid data number: {}\".format(len(train_dataset), len(val_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuroGenesis1(nn.Module):\n",
    "    def __init__(self,in_dim,out_dim,threshold=0.01):\n",
    "        super(NeuroGenesis1,self).__init__()\n",
    "        self.linear=nn.Linear(in_dim,out_dim)\n",
    "        self.threshold=threshold\n",
    "\n",
    "    def generate_number(self,n):\n",
    "        numbers=[]\n",
    "        while len(numbers)<n:\n",
    "            randn = torch.randn(1)\n",
    "            if randn >= self.threshold:\n",
    "                numbers.append(randn.item())\n",
    "        return numbers            \n",
    "\n",
    "    def forward(self,x):\n",
    "        if self.training:\n",
    "            if epoch >30:\n",
    "                mask=torch.abs(self.linear.weight) < self.threshold\n",
    "                self.linear.weight.data[mask]=0.0\n",
    "\n",
    "                mask=self.linear.weight==0.0\n",
    "                self.linear.weight.data[mask]=self.generate_number(mask.sum()).to(x.device)\n",
    "\n",
    "                x=self.linear(x)\n",
    "                return x\n",
    "            else:\n",
    "                return x\n",
    "            \n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeurogenesisModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeurogenesisModel, self).__init__()\n",
    "        self.conv1=nn.Conv2d(3, 32, 3)       # 32x32x3 -> 30x30x32\n",
    "        self.av1=nn.ReLU()\n",
    "        self.pool1=nn.AvgPool2d(2)                  # 30x30x32 -> 15x15x32\n",
    "        self.conv2=nn.Conv2d(32, 64, 3)             # 15x15x32 -> 13x13x64\n",
    "        self.av2=nn.ReLU()\n",
    "        self.pool2=nn.AvgPool2d(2)                  # 13x13x64 -> 6x6x64               # 4x4x128 -> 2x2x128\n",
    "        self.flatten=nn.Flatten()\n",
    "        self.neurogenesis=NeuroGenesis1(2304,256,0.01)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.fc2=nn.Linear(256, 10)\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.av1(x)\n",
    "        x=self.pool1(x)\n",
    "        x=self.conv2(x)\n",
    "        x=self.av2(x)\n",
    "        x=self.pool2(x)     \n",
    "        x=self.flatten(x)\n",
    "        x=self.neurogenesis(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model=NeurogenesisModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def init_weights(m):  # Heの初期化\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        torch.nn.init.kaiming_normal_(m.weight)\n",
    "        m.bias.data.fill_(0.0)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "device='cuda'\n",
    "model.to(device)\n",
    "optimizer2 = optim.Adam(model.parameters(), lr=config['lr'])\n",
    "loss_function = nn.CrossEntropyLoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (256x2304 and 256x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/bdr/deep-learning/neurogenesis/ChangeValue.ipynb セル 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bdr/deep-learning/neurogenesis/ChangeValue.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device)  \u001b[39m# テンソルをGPUに移動\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bdr/deep-learning/neurogenesis/ChangeValue.ipynb#W6sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/bdr/deep-learning/neurogenesis/ChangeValue.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m y \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward(x)  \u001b[39m# 順伝播\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bdr/deep-learning/neurogenesis/ChangeValue.ipynb#W6sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_function(y, t)  \u001b[39m# 誤差(クロスエントロピー誤差関数)の計算\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bdr/deep-learning/neurogenesis/ChangeValue.ipynb#W6sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()  \u001b[39m# 誤差の逆伝播\u001b[39;00m\n",
      "\u001b[1;32m/home/bdr/deep-learning/neurogenesis/ChangeValue.ipynb セル 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bdr/deep-learning/neurogenesis/ChangeValue.ipynb#W6sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m x\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneurogenesis(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bdr/deep-learning/neurogenesis/ChangeValue.ipynb#W6sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m x\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/bdr/deep-learning/neurogenesis/ChangeValue.ipynb#W6sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m x\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc2(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bdr/deep-learning/neurogenesis/ChangeValue.ipynb#W6sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (256x2304 and 256x10)"
     ]
    }
   ],
   "source": [
    "accuracy_train=[]\n",
    "cost_train=[]\n",
    "accuracy_valid=[]\n",
    "cost_valid=[]\n",
    "\n",
    "for epoch in range(config['n_epochs']):\n",
    "    losses_train = []\n",
    "    losses_valid = []\n",
    "\n",
    "    model.train()\n",
    "    n_train = 0\n",
    "    acc_train = 0\n",
    "    for x, t in dataloader_train:\n",
    "        n_train += t.size()[0]\n",
    "\n",
    "        model.zero_grad()  # 勾配の初期化\n",
    "\n",
    "        x = x.to(device)  # テンソルをGPUに移動\n",
    "        t = t.to(device)\n",
    "\n",
    "        y = model.forward(x)  # 順伝播\n",
    "\n",
    "\n",
    "        loss = loss_function(y, t)  # 誤差(クロスエントロピー誤差関数)の計算\n",
    "\n",
    "        loss.backward()  # 誤差の逆伝播\n",
    "\n",
    "        optimizer2.step()  # パラメータの更新\n",
    "\n",
    "        pred = y.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n",
    "\n",
    "        acc_train += (pred == t).float().sum().item()\n",
    "        losses_train.append(loss.tolist())\n",
    "\n",
    "    accuracy_train.append(acc_train/n_train)\n",
    "    cost_train.append(np.mean(losses_train))\n",
    "\n",
    "    model.eval()\n",
    "    n_val = 0\n",
    "    acc_val = 0\n",
    "    for x, t in dataloader_valid:\n",
    "        n_val += t.size()[0]\n",
    "\n",
    "        x = x.to(device)  # テンソルをGPUに移動\n",
    "        t = t.to(device)\n",
    "\n",
    "        y = model.forward(x)  # 順伝播\n",
    "\n",
    "        loss = loss_function(y, t)  # 誤差(クロスエントロピー誤差関数)の計算\n",
    "\n",
    "        pred = y.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n",
    "\n",
    "        acc_val += (pred == t).float().sum().item()\n",
    "        losses_valid.append(loss.tolist())\n",
    "    accuracy_valid.append(acc_val/n_val)\n",
    "    cost_valid.append(np.mean(losses_valid))\n",
    "\n",
    "    print('EPOCH: {}, Train [Loss: {:.3f}, Accuracy: {:.3f}], Valid [Loss: {:.3f}, Accuracy: {:.3f}]]'.format(\n",
    "        epoch+1,\n",
    "        np.mean(losses_train),\n",
    "        acc_train/n_train,\n",
    "        np.mean(losses_valid),\n",
    "        acc_val/n_val,\n",
    "    ))\n",
    "\n",
    "\n",
    "x=np.arange(1,config['n_epochs']+1,1)\n",
    "y1=accuracy_train\n",
    "y2=cost_train\n",
    "y3 = accuracy_valid\n",
    "y4 = cost_valid\n",
    "c1,c2= 'blue', 'orange'\n",
    "l1,l2,l3,l4 = 'accuracy_train', 'cost_train','accuracy_valid','cost_valid'\n",
    "xl1, xl2= 'epochs', 'epochs'\n",
    "yl1, yl2= 'accuracy', 'cost'\n",
    "fig = plt.figure(figsize = (20,6))\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax1.plot(x, y1, color=c1, label=l1)\n",
    "ax1.plot(x,y3,color=c2,label=l3)\n",
    "ax2.plot(x, y2, color=c1, label=l2)\n",
    "ax2.plot(x,y4,color=c2,label=l4)\n",
    "ax1.set_xlabel(xl1)\n",
    "ax2.set_xlabel(xl2)\n",
    "ax1.set_ylabel(yl1)\n",
    "ax2.set_ylabel(yl2)\n",
    "ax1.legend(loc = 'upper right')\n",
    "ax2.legend(loc = 'upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight (32, 3, 3, 3)\n",
      "bn1.weight (32,)\n",
      "conv2.weight (64, 32, 3, 3)\n",
      "bn2.weight (64,)\n",
      "conv3.weight (128, 64, 3, 3)\n",
      "bn3.weight (128,)\n",
      "neurogenesis.linear.weight (512, 512)\n",
      "fc2.weight (10, 512)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def save_weights(model, filename):\n",
    "    weights = {}\n",
    "\n",
    "    # モデルの各層の名前とパラメータを取得\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            weights[name] = param.detach().cpu().numpy()\n",
    "\n",
    "    # .npz ファイルとして出力\n",
    "    np.savez(filename, **weights)\n",
    "\n",
    "save_weights(model, 'weights.npz')\n",
    "data = np.load('weights.npz')\n",
    "\n",
    "for key in data.keys():\n",
    "    print(key, data[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "testset = torchvision.datasets.CIFAR10(root='data', train=False, download=True, transform=transforms.ToTensor() )\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "import pprint\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "prediction=[]\n",
    "label_list=[]\n",
    "# 勾配を記憶せず（学習せずに）に計算を行う\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device),data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        prediction.extend(predicted.tolist())\n",
    "        label_list.extend(labels.tolist())\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "\n",
    "metrix=confusion_matrix(prediction,label_list)\n",
    "print(classification_report(prediction,label_list))\n",
    "cmp = ConfusionMatrixDisplay(metrix)\n",
    "\n",
    "cmp.plot(cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_net2 = nn.Sequential(\n",
    "    nn.Conv2d(3, 32, 3),              # 32x32x3 -> 30x30x32\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(2),                  # 30x30x32 -> 15x15x32\n",
    "    nn.Conv2d(32, 64, 3),             # 15x15x32 -> 13x13x64\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(2),                  # 13x13x64 -> 6x6x64\n",
    "    nn.Conv2d(64, 128, 3),            # 6x6x64 -> 4x4x128\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(2),                  # 4x4x128 -> 2x2x128\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(2*2*128, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 10)\n",
    ")\n",
    "\n",
    "\n",
    "def init_weights(m):  # Heの初期化\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        torch.nn.init.kaiming_normal_(m.weight)\n",
    "        m.bias.data.fill_(0.0)\n",
    "\n",
    "\n",
    "conv_net2.apply(init_weights)\n",
    "\n",
    "batch_size = 100\n",
    "n_epochs = 5\n",
    "lr = 0.01\n",
    "device = 'cuda'\n",
    "\n",
    "conv_net2.to(device)\n",
    "optimizer2 = optim.Adam(conv_net2.parameters(), lr=lr)\n",
    "loss_function = nn.CrossEntropyLoss()  # nn.ClossEntropyLossは，出力のsoftmax変換と，正解ラベルのone-hot vector化の機能を持っている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1, Train [Loss: 1.449, Accuracy: 0.475], Valid [Loss: 1.406, Accuracy: 0.512]\n",
      "EPOCH: 2, Train [Loss: 1.030, Accuracy: 0.634], Valid [Loss: 1.046, Accuracy: 0.633]\n",
      "EPOCH: 3, Train [Loss: 0.852, Accuracy: 0.702], Valid [Loss: 1.264, Accuracy: 0.586]\n",
      "EPOCH: 4, Train [Loss: 0.743, Accuracy: 0.740], Valid [Loss: 0.910, Accuracy: 0.687]\n",
      "EPOCH: 5, Train [Loss: 0.648, Accuracy: 0.774], Valid [Loss: 1.053, Accuracy: 0.660]\n",
      "EPOCH: 6, Train [Loss: 0.591, Accuracy: 0.795], Valid [Loss: 0.970, Accuracy: 0.679]\n",
      "EPOCH: 7, Train [Loss: 0.520, Accuracy: 0.819], Valid [Loss: 0.836, Accuracy: 0.724]\n",
      "EPOCH: 8, Train [Loss: 0.477, Accuracy: 0.832], Valid [Loss: 0.871, Accuracy: 0.725]\n",
      "EPOCH: 9, Train [Loss: 0.427, Accuracy: 0.851], Valid [Loss: 1.016, Accuracy: 0.686]\n",
      "EPOCH: 10, Train [Loss: 0.386, Accuracy: 0.864], Valid [Loss: 1.011, Accuracy: 0.702]\n",
      "EPOCH: 11, Train [Loss: 0.343, Accuracy: 0.879], Valid [Loss: 1.091, Accuracy: 0.686]\n",
      "EPOCH: 12, Train [Loss: 0.316, Accuracy: 0.888], Valid [Loss: 0.970, Accuracy: 0.721]\n",
      "EPOCH: 13, Train [Loss: 0.282, Accuracy: 0.902], Valid [Loss: 1.020, Accuracy: 0.731]\n",
      "EPOCH: 14, Train [Loss: 0.266, Accuracy: 0.906], Valid [Loss: 1.034, Accuracy: 0.722]\n",
      "EPOCH: 15, Train [Loss: 0.250, Accuracy: 0.912], Valid [Loss: 1.043, Accuracy: 0.730]\n",
      "EPOCH: 16, Train [Loss: 0.221, Accuracy: 0.922], Valid [Loss: 1.190, Accuracy: 0.712]\n",
      "EPOCH: 17, Train [Loss: 0.205, Accuracy: 0.928], Valid [Loss: 1.222, Accuracy: 0.723]\n",
      "EPOCH: 18, Train [Loss: 0.187, Accuracy: 0.934], Valid [Loss: 1.153, Accuracy: 0.739]\n",
      "EPOCH: 19, Train [Loss: 0.184, Accuracy: 0.935], Valid [Loss: 1.370, Accuracy: 0.711]\n",
      "EPOCH: 20, Train [Loss: 0.159, Accuracy: 0.943], Valid [Loss: 1.388, Accuracy: 0.720]\n",
      "EPOCH: 21, Train [Loss: 0.158, Accuracy: 0.946], Valid [Loss: 1.261, Accuracy: 0.730]\n",
      "EPOCH: 22, Train [Loss: 0.143, Accuracy: 0.950], Valid [Loss: 1.342, Accuracy: 0.733]\n",
      "EPOCH: 23, Train [Loss: 0.150, Accuracy: 0.946], Valid [Loss: 1.670, Accuracy: 0.696]\n",
      "EPOCH: 24, Train [Loss: 0.143, Accuracy: 0.950], Valid [Loss: 1.418, Accuracy: 0.734]\n",
      "EPOCH: 25, Train [Loss: 0.124, Accuracy: 0.956], Valid [Loss: 1.609, Accuracy: 0.710]\n",
      "EPOCH: 26, Train [Loss: 0.129, Accuracy: 0.954], Valid [Loss: 1.350, Accuracy: 0.735]\n",
      "EPOCH: 27, Train [Loss: 0.110, Accuracy: 0.961], Valid [Loss: 1.482, Accuracy: 0.736]\n",
      "EPOCH: 28, Train [Loss: 0.117, Accuracy: 0.959], Valid [Loss: 1.654, Accuracy: 0.707]\n",
      "EPOCH: 29, Train [Loss: 0.118, Accuracy: 0.959], Valid [Loss: 2.185, Accuracy: 0.660]\n",
      "EPOCH: 30, Train [Loss: 0.113, Accuracy: 0.961], Valid [Loss: 1.867, Accuracy: 0.689]\n",
      "EPOCH: 31, Train [Loss: 0.104, Accuracy: 0.963], Valid [Loss: 1.530, Accuracy: 0.734]\n",
      "EPOCH: 32, Train [Loss: 0.098, Accuracy: 0.967], Valid [Loss: 1.802, Accuracy: 0.709]\n",
      "EPOCH: 33, Train [Loss: 0.102, Accuracy: 0.964], Valid [Loss: 1.593, Accuracy: 0.732]\n",
      "EPOCH: 34, Train [Loss: 0.094, Accuracy: 0.969], Valid [Loss: 1.752, Accuracy: 0.724]\n",
      "EPOCH: 35, Train [Loss: 0.092, Accuracy: 0.969], Valid [Loss: 2.097, Accuracy: 0.704]\n",
      "EPOCH: 36, Train [Loss: 0.094, Accuracy: 0.969], Valid [Loss: 2.077, Accuracy: 0.682]\n",
      "EPOCH: 37, Train [Loss: 0.109, Accuracy: 0.964], Valid [Loss: 1.561, Accuracy: 0.752]\n",
      "EPOCH: 38, Train [Loss: 0.070, Accuracy: 0.976], Valid [Loss: 1.850, Accuracy: 0.725]\n",
      "EPOCH: 39, Train [Loss: 0.089, Accuracy: 0.970], Valid [Loss: 1.661, Accuracy: 0.740]\n",
      "EPOCH: 40, Train [Loss: 0.076, Accuracy: 0.974], Valid [Loss: 2.680, Accuracy: 0.655]\n",
      "EPOCH: 41, Train [Loss: 0.090, Accuracy: 0.970], Valid [Loss: 1.711, Accuracy: 0.737]\n",
      "EPOCH: 42, Train [Loss: 0.077, Accuracy: 0.974], Valid [Loss: 1.756, Accuracy: 0.730]\n",
      "EPOCH: 43, Train [Loss: 0.072, Accuracy: 0.975], Valid [Loss: 1.744, Accuracy: 0.734]\n",
      "EPOCH: 44, Train [Loss: 0.091, Accuracy: 0.969], Valid [Loss: 1.674, Accuracy: 0.736]\n",
      "EPOCH: 45, Train [Loss: 0.061, Accuracy: 0.979], Valid [Loss: 1.862, Accuracy: 0.740]\n",
      "EPOCH: 46, Train [Loss: 0.074, Accuracy: 0.975], Valid [Loss: 1.973, Accuracy: 0.723]\n",
      "EPOCH: 47, Train [Loss: 0.083, Accuracy: 0.972], Valid [Loss: 1.903, Accuracy: 0.726]\n",
      "EPOCH: 48, Train [Loss: 0.084, Accuracy: 0.973], Valid [Loss: 1.750, Accuracy: 0.738]\n",
      "EPOCH: 49, Train [Loss: 0.055, Accuracy: 0.981], Valid [Loss: 2.389, Accuracy: 0.699]\n",
      "EPOCH: 50, Train [Loss: 0.077, Accuracy: 0.974], Valid [Loss: 1.921, Accuracy: 0.735]\n",
      "EPOCH: 51, Train [Loss: 0.068, Accuracy: 0.977], Valid [Loss: 1.840, Accuracy: 0.745]\n",
      "EPOCH: 52, Train [Loss: 0.057, Accuracy: 0.981], Valid [Loss: 1.868, Accuracy: 0.738]\n",
      "EPOCH: 53, Train [Loss: 0.081, Accuracy: 0.975], Valid [Loss: 2.074, Accuracy: 0.711]\n",
      "EPOCH: 54, Train [Loss: 0.071, Accuracy: 0.976], Valid [Loss: 1.908, Accuracy: 0.733]\n",
      "EPOCH: 55, Train [Loss: 0.074, Accuracy: 0.976], Valid [Loss: 1.860, Accuracy: 0.741]\n",
      "EPOCH: 56, Train [Loss: 0.049, Accuracy: 0.984], Valid [Loss: 1.860, Accuracy: 0.749]\n",
      "EPOCH: 57, Train [Loss: 0.057, Accuracy: 0.981], Valid [Loss: 2.242, Accuracy: 0.719]\n",
      "EPOCH: 58, Train [Loss: 0.076, Accuracy: 0.975], Valid [Loss: 2.078, Accuracy: 0.727]\n",
      "EPOCH: 59, Train [Loss: 0.073, Accuracy: 0.977], Valid [Loss: 1.828, Accuracy: 0.747]\n",
      "EPOCH: 60, Train [Loss: 0.049, Accuracy: 0.984], Valid [Loss: 2.289, Accuracy: 0.719]\n",
      "EPOCH: 61, Train [Loss: 0.067, Accuracy: 0.979], Valid [Loss: 1.983, Accuracy: 0.734]\n",
      "EPOCH: 62, Train [Loss: 0.061, Accuracy: 0.980], Valid [Loss: 1.945, Accuracy: 0.747]\n",
      "EPOCH: 63, Train [Loss: 0.053, Accuracy: 0.983], Valid [Loss: 2.195, Accuracy: 0.723]\n",
      "EPOCH: 64, Train [Loss: 0.052, Accuracy: 0.983], Valid [Loss: 2.016, Accuracy: 0.742]\n",
      "EPOCH: 65, Train [Loss: 0.061, Accuracy: 0.981], Valid [Loss: 2.220, Accuracy: 0.721]\n",
      "EPOCH: 66, Train [Loss: 0.062, Accuracy: 0.980], Valid [Loss: 2.128, Accuracy: 0.732]\n",
      "EPOCH: 67, Train [Loss: 0.068, Accuracy: 0.978], Valid [Loss: 2.023, Accuracy: 0.741]\n",
      "EPOCH: 68, Train [Loss: 0.055, Accuracy: 0.982], Valid [Loss: 2.282, Accuracy: 0.719]\n",
      "EPOCH: 69, Train [Loss: 0.058, Accuracy: 0.981], Valid [Loss: 2.050, Accuracy: 0.752]\n",
      "EPOCH: 70, Train [Loss: 0.049, Accuracy: 0.984], Valid [Loss: 2.095, Accuracy: 0.739]\n",
      "EPOCH: 71, Train [Loss: 0.058, Accuracy: 0.981], Valid [Loss: 2.090, Accuracy: 0.745]\n",
      "EPOCH: 72, Train [Loss: 0.055, Accuracy: 0.982], Valid [Loss: 2.395, Accuracy: 0.721]\n",
      "EPOCH: 73, Train [Loss: 0.056, Accuracy: 0.982], Valid [Loss: 2.175, Accuracy: 0.739]\n",
      "EPOCH: 74, Train [Loss: 0.046, Accuracy: 0.985], Valid [Loss: 2.009, Accuracy: 0.750]\n",
      "EPOCH: 75, Train [Loss: 0.053, Accuracy: 0.983], Valid [Loss: 2.705, Accuracy: 0.701]\n",
      "EPOCH: 76, Train [Loss: 0.057, Accuracy: 0.982], Valid [Loss: 2.197, Accuracy: 0.728]\n",
      "EPOCH: 77, Train [Loss: 0.041, Accuracy: 0.987], Valid [Loss: 2.229, Accuracy: 0.741]\n",
      "EPOCH: 78, Train [Loss: 0.066, Accuracy: 0.979], Valid [Loss: 2.656, Accuracy: 0.721]\n",
      "EPOCH: 79, Train [Loss: 0.057, Accuracy: 0.982], Valid [Loss: 2.725, Accuracy: 0.705]\n",
      "EPOCH: 80, Train [Loss: 0.046, Accuracy: 0.985], Valid [Loss: 2.038, Accuracy: 0.747]\n",
      "EPOCH: 81, Train [Loss: 0.053, Accuracy: 0.984], Valid [Loss: 2.552, Accuracy: 0.715]\n",
      "EPOCH: 82, Train [Loss: 0.050, Accuracy: 0.983], Valid [Loss: 2.353, Accuracy: 0.737]\n",
      "EPOCH: 83, Train [Loss: 0.056, Accuracy: 0.982], Valid [Loss: 2.123, Accuracy: 0.744]\n",
      "EPOCH: 84, Train [Loss: 0.049, Accuracy: 0.984], Valid [Loss: 2.078, Accuracy: 0.743]\n",
      "EPOCH: 85, Train [Loss: 0.057, Accuracy: 0.982], Valid [Loss: 2.081, Accuracy: 0.748]\n",
      "EPOCH: 86, Train [Loss: 0.045, Accuracy: 0.987], Valid [Loss: 2.070, Accuracy: 0.759]\n",
      "EPOCH: 87, Train [Loss: 0.042, Accuracy: 0.987], Valid [Loss: 2.119, Accuracy: 0.746]\n",
      "EPOCH: 88, Train [Loss: 0.046, Accuracy: 0.985], Valid [Loss: 2.450, Accuracy: 0.723]\n",
      "EPOCH: 89, Train [Loss: 0.045, Accuracy: 0.985], Valid [Loss: 2.540, Accuracy: 0.730]\n",
      "EPOCH: 90, Train [Loss: 0.056, Accuracy: 0.983], Valid [Loss: 2.206, Accuracy: 0.736]\n",
      "EPOCH: 91, Train [Loss: 0.043, Accuracy: 0.987], Valid [Loss: 2.274, Accuracy: 0.743]\n",
      "EPOCH: 92, Train [Loss: 0.040, Accuracy: 0.987], Valid [Loss: 2.159, Accuracy: 0.752]\n",
      "EPOCH: 93, Train [Loss: 0.044, Accuracy: 0.986], Valid [Loss: 2.280, Accuracy: 0.741]\n",
      "EPOCH: 94, Train [Loss: 0.053, Accuracy: 0.983], Valid [Loss: 2.234, Accuracy: 0.752]\n",
      "EPOCH: 95, Train [Loss: 0.054, Accuracy: 0.983], Valid [Loss: 2.381, Accuracy: 0.735]\n",
      "EPOCH: 96, Train [Loss: 0.051, Accuracy: 0.985], Valid [Loss: 2.325, Accuracy: 0.724]\n",
      "EPOCH: 97, Train [Loss: 0.040, Accuracy: 0.988], Valid [Loss: 2.330, Accuracy: 0.742]\n",
      "EPOCH: 98, Train [Loss: 0.046, Accuracy: 0.986], Valid [Loss: 3.123, Accuracy: 0.686]\n",
      "EPOCH: 99, Train [Loss: 0.055, Accuracy: 0.983], Valid [Loss: 2.259, Accuracy: 0.744]\n",
      "EPOCH: 100, Train [Loss: 0.050, Accuracy: 0.985], Valid [Loss: 2.470, Accuracy: 0.735]\n",
      "EPOCH: 101, Train [Loss: 0.035, Accuracy: 0.989], Valid [Loss: 2.345, Accuracy: 0.744]\n",
      "EPOCH: 102, Train [Loss: 0.039, Accuracy: 0.988], Valid [Loss: 2.286, Accuracy: 0.742]\n",
      "EPOCH: 103, Train [Loss: 0.049, Accuracy: 0.985], Valid [Loss: 2.280, Accuracy: 0.744]\n",
      "EPOCH: 104, Train [Loss: 0.043, Accuracy: 0.987], Valid [Loss: 2.323, Accuracy: 0.746]\n",
      "EPOCH: 105, Train [Loss: 0.047, Accuracy: 0.985], Valid [Loss: 2.418, Accuracy: 0.746]\n",
      "EPOCH: 106, Train [Loss: 0.043, Accuracy: 0.987], Valid [Loss: 2.189, Accuracy: 0.747]\n",
      "EPOCH: 107, Train [Loss: 0.045, Accuracy: 0.986], Valid [Loss: 2.272, Accuracy: 0.750]\n",
      "EPOCH: 108, Train [Loss: 0.030, Accuracy: 0.991], Valid [Loss: 2.605, Accuracy: 0.742]\n",
      "EPOCH: 109, Train [Loss: 0.046, Accuracy: 0.986], Valid [Loss: 2.534, Accuracy: 0.740]\n",
      "EPOCH: 110, Train [Loss: 0.051, Accuracy: 0.985], Valid [Loss: 2.369, Accuracy: 0.746]\n",
      "EPOCH: 111, Train [Loss: 0.036, Accuracy: 0.989], Valid [Loss: 2.929, Accuracy: 0.714]\n",
      "EPOCH: 112, Train [Loss: 0.048, Accuracy: 0.986], Valid [Loss: 2.407, Accuracy: 0.734]\n",
      "EPOCH: 113, Train [Loss: 0.043, Accuracy: 0.987], Valid [Loss: 2.472, Accuracy: 0.739]\n",
      "EPOCH: 114, Train [Loss: 0.038, Accuracy: 0.989], Valid [Loss: 2.517, Accuracy: 0.741]\n",
      "EPOCH: 115, Train [Loss: 0.041, Accuracy: 0.987], Valid [Loss: 2.446, Accuracy: 0.748]\n",
      "EPOCH: 116, Train [Loss: 0.047, Accuracy: 0.986], Valid [Loss: 3.540, Accuracy: 0.673]\n",
      "EPOCH: 117, Train [Loss: 0.047, Accuracy: 0.987], Valid [Loss: 2.622, Accuracy: 0.738]\n",
      "EPOCH: 118, Train [Loss: 0.053, Accuracy: 0.984], Valid [Loss: 2.472, Accuracy: 0.740]\n",
      "EPOCH: 119, Train [Loss: 0.040, Accuracy: 0.988], Valid [Loss: 2.422, Accuracy: 0.757]\n",
      "EPOCH: 120, Train [Loss: 0.031, Accuracy: 0.990], Valid [Loss: 2.517, Accuracy: 0.746]\n",
      "EPOCH: 121, Train [Loss: 0.030, Accuracy: 0.991], Valid [Loss: 2.510, Accuracy: 0.751]\n",
      "EPOCH: 122, Train [Loss: 0.038, Accuracy: 0.989], Valid [Loss: 2.696, Accuracy: 0.743]\n",
      "EPOCH: 123, Train [Loss: 0.048, Accuracy: 0.985], Valid [Loss: 2.421, Accuracy: 0.744]\n",
      "EPOCH: 124, Train [Loss: 0.032, Accuracy: 0.990], Valid [Loss: 2.650, Accuracy: 0.741]\n",
      "EPOCH: 125, Train [Loss: 0.043, Accuracy: 0.988], Valid [Loss: 2.445, Accuracy: 0.740]\n",
      "EPOCH: 126, Train [Loss: 0.032, Accuracy: 0.991], Valid [Loss: 2.998, Accuracy: 0.724]\n",
      "EPOCH: 127, Train [Loss: 0.049, Accuracy: 0.986], Valid [Loss: 2.759, Accuracy: 0.742]\n",
      "EPOCH: 128, Train [Loss: 0.039, Accuracy: 0.988], Valid [Loss: 2.601, Accuracy: 0.749]\n",
      "EPOCH: 129, Train [Loss: 0.043, Accuracy: 0.988], Valid [Loss: 2.821, Accuracy: 0.733]\n",
      "EPOCH: 130, Train [Loss: 0.047, Accuracy: 0.986], Valid [Loss: 2.375, Accuracy: 0.750]\n",
      "EPOCH: 131, Train [Loss: 0.031, Accuracy: 0.991], Valid [Loss: 2.994, Accuracy: 0.720]\n",
      "EPOCH: 132, Train [Loss: 0.037, Accuracy: 0.989], Valid [Loss: 2.681, Accuracy: 0.747]\n",
      "EPOCH: 133, Train [Loss: 0.033, Accuracy: 0.990], Valid [Loss: 2.733, Accuracy: 0.742]\n",
      "EPOCH: 134, Train [Loss: 0.042, Accuracy: 0.988], Valid [Loss: 2.918, Accuracy: 0.738]\n",
      "EPOCH: 135, Train [Loss: 0.033, Accuracy: 0.990], Valid [Loss: 2.796, Accuracy: 0.740]\n",
      "EPOCH: 136, Train [Loss: 0.052, Accuracy: 0.985], Valid [Loss: 2.556, Accuracy: 0.747]\n",
      "EPOCH: 137, Train [Loss: 0.040, Accuracy: 0.989], Valid [Loss: 2.843, Accuracy: 0.732]\n",
      "EPOCH: 138, Train [Loss: 0.034, Accuracy: 0.990], Valid [Loss: 2.543, Accuracy: 0.744]\n",
      "EPOCH: 139, Train [Loss: 0.032, Accuracy: 0.991], Valid [Loss: 2.506, Accuracy: 0.746]\n",
      "EPOCH: 140, Train [Loss: 0.038, Accuracy: 0.989], Valid [Loss: 2.560, Accuracy: 0.752]\n",
      "EPOCH: 141, Train [Loss: 0.037, Accuracy: 0.989], Valid [Loss: 2.633, Accuracy: 0.742]\n",
      "EPOCH: 142, Train [Loss: 0.037, Accuracy: 0.990], Valid [Loss: 2.776, Accuracy: 0.747]\n",
      "EPOCH: 143, Train [Loss: 0.027, Accuracy: 0.992], Valid [Loss: 2.826, Accuracy: 0.746]\n",
      "EPOCH: 144, Train [Loss: 0.048, Accuracy: 0.987], Valid [Loss: 2.840, Accuracy: 0.736]\n",
      "EPOCH: 145, Train [Loss: 0.049, Accuracy: 0.986], Valid [Loss: 2.796, Accuracy: 0.743]\n",
      "EPOCH: 146, Train [Loss: 0.039, Accuracy: 0.989], Valid [Loss: 2.902, Accuracy: 0.737]\n",
      "EPOCH: 147, Train [Loss: 0.050, Accuracy: 0.986], Valid [Loss: 2.554, Accuracy: 0.753]\n",
      "EPOCH: 148, Train [Loss: 0.031, Accuracy: 0.991], Valid [Loss: 2.615, Accuracy: 0.752]\n",
      "EPOCH: 149, Train [Loss: 0.026, Accuracy: 0.992], Valid [Loss: 2.802, Accuracy: 0.747]\n",
      "EPOCH: 150, Train [Loss: 0.034, Accuracy: 0.991], Valid [Loss: 2.675, Accuracy: 0.750]\n",
      "EPOCH: 151, Train [Loss: 0.041, Accuracy: 0.989], Valid [Loss: 2.900, Accuracy: 0.739]\n",
      "EPOCH: 152, Train [Loss: 0.047, Accuracy: 0.987], Valid [Loss: 2.503, Accuracy: 0.753]\n",
      "EPOCH: 153, Train [Loss: 0.030, Accuracy: 0.992], Valid [Loss: 2.659, Accuracy: 0.747]\n",
      "EPOCH: 154, Train [Loss: 0.029, Accuracy: 0.991], Valid [Loss: 2.758, Accuracy: 0.750]\n",
      "EPOCH: 155, Train [Loss: 0.029, Accuracy: 0.992], Valid [Loss: 2.626, Accuracy: 0.752]\n",
      "EPOCH: 156, Train [Loss: 0.032, Accuracy: 0.991], Valid [Loss: 3.036, Accuracy: 0.733]\n",
      "EPOCH: 157, Train [Loss: 0.044, Accuracy: 0.988], Valid [Loss: 3.326, Accuracy: 0.723]\n",
      "EPOCH: 158, Train [Loss: 0.029, Accuracy: 0.991], Valid [Loss: 2.852, Accuracy: 0.746]\n",
      "EPOCH: 159, Train [Loss: 0.045, Accuracy: 0.988], Valid [Loss: 2.925, Accuracy: 0.742]\n",
      "EPOCH: 160, Train [Loss: 0.052, Accuracy: 0.986], Valid [Loss: 2.683, Accuracy: 0.749]\n",
      "EPOCH: 161, Train [Loss: 0.027, Accuracy: 0.992], Valid [Loss: 2.710, Accuracy: 0.755]\n",
      "EPOCH: 162, Train [Loss: 0.028, Accuracy: 0.992], Valid [Loss: 2.790, Accuracy: 0.750]\n",
      "EPOCH: 163, Train [Loss: 0.035, Accuracy: 0.990], Valid [Loss: 2.711, Accuracy: 0.749]\n",
      "EPOCH: 164, Train [Loss: 0.043, Accuracy: 0.988], Valid [Loss: 2.957, Accuracy: 0.741]\n",
      "EPOCH: 165, Train [Loss: 0.039, Accuracy: 0.989], Valid [Loss: 2.881, Accuracy: 0.741]\n",
      "EPOCH: 166, Train [Loss: 0.031, Accuracy: 0.991], Valid [Loss: 2.714, Accuracy: 0.757]\n",
      "EPOCH: 167, Train [Loss: 0.022, Accuracy: 0.993], Valid [Loss: 2.892, Accuracy: 0.751]\n",
      "EPOCH: 168, Train [Loss: 0.043, Accuracy: 0.988], Valid [Loss: 3.184, Accuracy: 0.720]\n",
      "EPOCH: 169, Train [Loss: 0.051, Accuracy: 0.987], Valid [Loss: 3.015, Accuracy: 0.726]\n",
      "EPOCH: 170, Train [Loss: 0.039, Accuracy: 0.990], Valid [Loss: 2.725, Accuracy: 0.749]\n",
      "EPOCH: 171, Train [Loss: 0.025, Accuracy: 0.993], Valid [Loss: 2.721, Accuracy: 0.749]\n",
      "EPOCH: 172, Train [Loss: 0.015, Accuracy: 0.996], Valid [Loss: 2.862, Accuracy: 0.753]\n",
      "EPOCH: 173, Train [Loss: 0.036, Accuracy: 0.990], Valid [Loss: 2.817, Accuracy: 0.759]\n",
      "EPOCH: 174, Train [Loss: 0.041, Accuracy: 0.989], Valid [Loss: 2.887, Accuracy: 0.751]\n",
      "EPOCH: 175, Train [Loss: 0.046, Accuracy: 0.987], Valid [Loss: 3.111, Accuracy: 0.728]\n",
      "EPOCH: 176, Train [Loss: 0.028, Accuracy: 0.992], Valid [Loss: 3.011, Accuracy: 0.741]\n",
      "EPOCH: 177, Train [Loss: 0.038, Accuracy: 0.990], Valid [Loss: 2.893, Accuracy: 0.752]\n",
      "EPOCH: 178, Train [Loss: 0.028, Accuracy: 0.992], Valid [Loss: 2.845, Accuracy: 0.756]\n",
      "EPOCH: 179, Train [Loss: 0.037, Accuracy: 0.990], Valid [Loss: 2.847, Accuracy: 0.749]\n",
      "EPOCH: 180, Train [Loss: 0.034, Accuracy: 0.991], Valid [Loss: 2.909, Accuracy: 0.755]\n",
      "EPOCH: 181, Train [Loss: 0.034, Accuracy: 0.991], Valid [Loss: 2.940, Accuracy: 0.747]\n",
      "EPOCH: 182, Train [Loss: 0.033, Accuracy: 0.991], Valid [Loss: 2.780, Accuracy: 0.751]\n",
      "EPOCH: 183, Train [Loss: 0.027, Accuracy: 0.992], Valid [Loss: 2.851, Accuracy: 0.751]\n",
      "EPOCH: 184, Train [Loss: 0.034, Accuracy: 0.991], Valid [Loss: 2.978, Accuracy: 0.743]\n",
      "EPOCH: 185, Train [Loss: 0.041, Accuracy: 0.990], Valid [Loss: 3.166, Accuracy: 0.742]\n",
      "EPOCH: 186, Train [Loss: 0.039, Accuracy: 0.990], Valid [Loss: 3.063, Accuracy: 0.750]\n",
      "EPOCH: 187, Train [Loss: 0.022, Accuracy: 0.993], Valid [Loss: 3.152, Accuracy: 0.740]\n",
      "EPOCH: 188, Train [Loss: 0.031, Accuracy: 0.991], Valid [Loss: 2.866, Accuracy: 0.748]\n",
      "EPOCH: 189, Train [Loss: 0.037, Accuracy: 0.990], Valid [Loss: 3.072, Accuracy: 0.742]\n",
      "EPOCH: 190, Train [Loss: 0.034, Accuracy: 0.991], Valid [Loss: 3.023, Accuracy: 0.747]\n",
      "EPOCH: 191, Train [Loss: 0.035, Accuracy: 0.991], Valid [Loss: 2.976, Accuracy: 0.750]\n",
      "EPOCH: 192, Train [Loss: 0.041, Accuracy: 0.989], Valid [Loss: 3.017, Accuracy: 0.756]\n",
      "EPOCH: 193, Train [Loss: 0.033, Accuracy: 0.991], Valid [Loss: 3.174, Accuracy: 0.753]\n",
      "EPOCH: 194, Train [Loss: 0.027, Accuracy: 0.992], Valid [Loss: 3.092, Accuracy: 0.744]\n",
      "EPOCH: 195, Train [Loss: 0.027, Accuracy: 0.992], Valid [Loss: 3.011, Accuracy: 0.748]\n",
      "EPOCH: 196, Train [Loss: 0.031, Accuracy: 0.992], Valid [Loss: 2.892, Accuracy: 0.747]\n",
      "EPOCH: 197, Train [Loss: 0.040, Accuracy: 0.990], Valid [Loss: 3.059, Accuracy: 0.747]\n",
      "EPOCH: 198, Train [Loss: 0.044, Accuracy: 0.989], Valid [Loss: 2.904, Accuracy: 0.749]\n",
      "EPOCH: 199, Train [Loss: 0.037, Accuracy: 0.990], Valid [Loss: 3.035, Accuracy: 0.746]\n",
      "EPOCH: 200, Train [Loss: 0.033, Accuracy: 0.990], Valid [Loss: 2.961, Accuracy: 0.753]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(config['n_epochs']):\n",
    "    losses_train = []\n",
    "    losses_valid = []\n",
    "\n",
    "    conv_net2.train()\n",
    "    n_train = 0\n",
    "    acc_train = 0\n",
    "    for x, t in dataloader_train:\n",
    "        n_train += t.size()[0]\n",
    "\n",
    "        conv_net2.zero_grad()  # 勾配の初期化\n",
    "\n",
    "        x = x.to(device)  # テンソルをGPUに移動\n",
    "        t = t.to(device)\n",
    "\n",
    "        y = conv_net2.forward(x)  # 順伝播\n",
    "\n",
    "        loss = loss_function(y, t)  # 誤差(クロスエントロピー誤差関数)の計算\n",
    "\n",
    "        loss.backward()  # 誤差の逆伝播\n",
    "\n",
    "        optimizer2.step()  # パラメータの更新\n",
    "\n",
    "        pred = y.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n",
    "\n",
    "        acc_train += (pred == t).float().sum().item()\n",
    "        losses_train.append(loss.tolist())\n",
    "\n",
    "    conv_net2.eval()\n",
    "    n_val = 0\n",
    "    acc_val = 0\n",
    "    for x, t in dataloader_valid:\n",
    "        n_val += t.size()[0]\n",
    "\n",
    "        x = x.to(device)  # テンソルをGPUに移動\n",
    "        t = t.to(device)\n",
    "\n",
    "        y = conv_net2.forward(x)  # 順伝播\n",
    "\n",
    "        loss = loss_function(y, t)  # 誤差(クロスエントロピー誤差関数)の計算\n",
    "\n",
    "        pred = y.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n",
    "\n",
    "        acc_val += (pred == t).float().sum().item()\n",
    "        losses_valid.append(loss.tolist())\n",
    "\n",
    "    print('EPOCH: {}, Train [Loss: {:.3f}, Accuracy: {:.3f}], Valid [Loss: {:.3f}, Accuracy: {:.3f}]'.format(\n",
    "        epoch+1,\n",
    "        np.mean(losses_train),\n",
    "        acc_train/n_train,\n",
    "        np.mean(losses_valid),\n",
    "        acc_val/n_val\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Accuracy of the network on the 10000 test images: 32 %\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor() )\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "# 勾配を記憶せず（学習せずに）に計算を行う\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device),data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/bdr/deep-learning/neurogenesis/ChangeValue.ipynb セル 12\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bdr/deep-learning/neurogenesis/ChangeValue.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bdr/deep-learning/neurogenesis/ChangeValue.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m confusion_matrix\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/bdr/deep-learning/neurogenesis/ChangeValue.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m testset \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mdatasets\u001b[39m.\u001b[39mCIFAR10(root\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./data\u001b[39m\u001b[39m'\u001b[39m, train\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, download\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, transform\u001b[39m=\u001b[39mtransforms\u001b[39m.\u001b[39mToTensor() )\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bdr/deep-learning/neurogenesis/ChangeValue.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m testloader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(testset, batch_size\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, num_workers\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bdr/deep-learning/neurogenesis/ChangeValue.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m correct \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor() )\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# 勾配を記憶せず（学習せずに）に計算を行う\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = conv_net2(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
